[data]
train_data = ./data/cache_set/train_set.json
valid_data = ./data/cache_set/valid_set.json
test_data =  ./data/cache_set/test_set.json
valid_data_raw = ./data/cache_set/valid_set_raw.json
test_data_raw =  ./data/cache_set/test_set_raw.json
train_data_raw = ./data/cache_set/train_set_raw.json
data_Lecard=./data/train_raw/Lecard_query_raw_candidate_raw1.json
query_key=query_crime


[test]
pos_score = 2
k_list =1,3,5,7,9,10,20,30,40,50,60,70
metric_list = MAP, MRR,P@k, R@k, NDCG@k

test_baseline = False
baseline_ids = 1,2,3,4,5,6,7,8,9,10,11,12

batch_size=8
test_ours = True
test_specific = None


[encoder]
backbone = lawformer
shared = True
pooling = avg



[train]
struct_encoder = False
checkpoint = None

struct_key=struct_incase
candidate_key=inputs_candidates

epoch = 100
evidence_sample_num = 1



batch_size = 1
positive_batch=2
negative_batch=22

grad_accumulate = 2
save_step = 20
logging_step = 4

sub_batch_size =8
sub_batch_size_gpu=24

optimizer = adamw

learning_rate = 1e-5
weight_decay = 0
step_size = 1
lr_multiplier = 1
reader_num = 1
fp16 = False


[simcse_loss]
use = True

negatives_parallel = False
negatives_cross = False

negatives_parallel_single = False

sim_fct = cos
temperature = 0.07
query_only =True

[attention_loss]
use = False
separate_attention_peak = False


[contra_loss]
use = True
rm_simcse = False

positive_attention = False
positive_query = True


query = bi-direction
value_sample_num = 1

negatives_attention = False
remove_hard_attention = False

negatives_value = False
neg_value_key = double

negatives_query = True
neg_query_key = double
remove_hard_query = False

sim_fct = cos
temperature = 0.2



[attention]
type = dot
scale = 1.0
temperature = 0.1


[positive_weight]
use = False
range = in_batch
normalize = soft

source = dot
type = norm
log_sum = True


[output] #output parameters
output_time = 1
test_time = 1

model_path = ./output/unified


[baseline]
pooling = avg

model1 = bert
model2 = bert-tiny
model3 = albert
model4 = roberta
model5 = ernie
model6 = mengzi
model7 = lawformer
model8 = legal-simcse
model9 = sbert

model10 = tfidf
model11 = bm25
model12 = boe

